GpuFreq=control_disabled
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:07<00:22,  7.62s/it]Loading checkpoint shards:  50%|█████     | 2/4 [00:14<00:14,  7.02s/it]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:28<00:10, 10.45s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:30<00:00,  6.92s/it]Loading checkpoint shards: 100%|██████████| 4/4 [00:30<00:00,  7.57s/it]
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]Loading checkpoint shards:  33%|███▎      | 1/3 [00:08<00:17,  8.99s/it]Loading checkpoint shards:  67%|██████▋   | 2/3 [00:18<00:09,  9.05s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:27<00:00,  9.09s/it]Loading checkpoint shards: 100%|██████████| 3/3 [00:27<00:00,  9.08s/it]
/pfs/data5/home/hd/hd_hd/hd_go226/projects/data_contamination/.venv/lib/python3.11/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.5` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.
Loading checkpoint shards:   0%|          | 0/6 [00:00<?, ?it/s]Loading checkpoint shards:  17%|█▋        | 1/6 [00:07<00:36,  7.35s/it]Loading checkpoint shards:  33%|███▎      | 2/6 [00:16<00:34,  8.64s/it]Loading checkpoint shards:  50%|█████     | 3/6 [00:25<00:25,  8.67s/it]Loading checkpoint shards:  67%|██████▋   | 4/6 [00:32<00:15,  7.99s/it]Loading checkpoint shards:  83%|████████▎ | 5/6 [00:38<00:07,  7.25s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:45<00:00,  7.15s/it]Loading checkpoint shards: 100%|██████████| 6/6 [00:45<00:00,  7.57s/it]
